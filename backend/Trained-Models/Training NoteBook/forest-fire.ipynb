{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11912236,"sourceType":"datasetVersion","datasetId":7488934},{"sourceId":11912275,"sourceType":"datasetVersion","datasetId":7488964},{"sourceId":11921422,"sourceType":"datasetVersion","datasetId":7494924}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"hlo\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T08:21:15.180932Z","iopub.execute_input":"2025-05-23T08:21:15.181123Z","iopub.status.idle":"2025-05-23T08:21:15.187621Z","shell.execute_reply.started":"2025-05-23T08:21:15.181106Z","shell.execute_reply":"2025-05-23T08:21:15.187012Z"}},"outputs":[{"name":"stdout","text":"hlo\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"dataset_path = r\"/kaggle/input/forest-fire-dataset\"\ntest_dir = r\"/kaggle/input/forest-fire-dataset/test\"\ntrain_dir = r\"/kaggle/input/forest-fire-dataset/train\"\ndata_splitting_path = r\"/kaggle/input/data-splitting/Data splitting\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T11:43:35.722183Z","iopub.execute_input":"2025-05-23T11:43:35.722654Z","iopub.status.idle":"2025-05-23T11:43:35.728882Z","shell.execute_reply.started":"2025-05-23T11:43:35.722626Z","shell.execute_reply":"2025-05-23T11:43:35.728138Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install ultralytics --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:23:30.714779Z","iopub.execute_input":"2025-05-23T13:23:30.715043Z","iopub.status.idle":"2025-05-23T13:24:50.066118Z","shell.execute_reply.started":"2025-05-23T13:23:30.715019Z","shell.execute_reply":"2025-05-23T13:24:50.065357Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport shutil\nimport glob # Use glob for robust file listing\n\n# --- Configuration ---\n\n# Path to the ORIGINAL dataset in /kaggle/input (read-only)\noriginal_dataset_path = r\"/kaggle/input/forest-fire-dataset\"\noriginal_train_images = os.path.join(original_dataset_path, \"train\", \"images\")\noriginal_train_labels = os.path.join(original_dataset_path, \"train\", \"labels\")\noriginal_test_images = os.path.join(original_dataset_path, \"test\", \"images\")\noriginal_test_labels = os.path.join(original_dataset_path, \"test\", \"labels\")\n\n\n# Path for the NEW working copy of the dataset in /kaggle/working (writable)\nworking_dataset_path = r\"/kaggle/working/dfire_working_copy\"\nworking_train_images = os.path.join(working_dataset_path, \"train\", \"images\")\nworking_train_labels = os.path.join(working_dataset_path, \"train\", \"labels\")\nworking_val_images = os.path.join(working_dataset_path, \"val\", \"images\")\nworking_val_labels = os.path.join(working_dataset_path, \"val\", \"labels\")\nworking_test_images = os.path.join(working_dataset_path, \"test\", \"images\")\nworking_test_labels = os.path.join(working_dataset_path, \"test\", \"labels\")\n\n\n# Define the percentage of the *original* training data to use for validation\nvalidation_split_percentage = 0.10 # 10% for validation\n\n# Define the classes (based on your dataset exploration: 0=Fire, 1=Smoke)\nclass_names = ['Fire', 'Smoke']\nnum_classes = len(class_names)\n\n# --- Step 1: Copy Original Data to Working Directory ---\nprint(f\"Copying dataset from {original_dataset_path} to writable {working_dataset_path}\")\n\n# Create working directories\nos.makedirs(working_train_images, exist_ok=True)\nos.makedirs(working_train_labels, exist_ok=True)\nos.makedirs(working_test_images, exist_ok=True)\nos.makedirs(working_test_labels, exist_ok=True)\nos.makedirs(working_val_images, exist_ok=True) # Create val now, will populate later\nos.makedirs(working_val_labels, exist_ok=True) # Create val now, will populate later\n\n# Copy Train Data\nprint(\"Copying train images and labels...\")\ntrain_image_files = glob.glob(os.path.join(original_train_images, '*.*'))\nfor img_src_path in train_image_files:\n    if os.path.isfile(img_src_path):\n        img_name = os.path.basename(img_src_path)\n        label_name = os.path.splitext(img_name)[0] + \".txt\"\n        label_src_path = os.path.join(original_train_labels, label_name)\n\n        img_dst_path = os.path.join(working_train_images, img_name)\n        label_dst_path = os.path.join(working_train_labels, label_name)\n\n        try:\n            shutil.copy2(img_src_path, img_dst_path)\n            if os.path.exists(label_src_path): # Copy label only if it exists\n                 shutil.copy2(label_src_path, label_dst_path)\n            # If label doesn't exist, it's a negative sample - that's fine, no label needed in working copy either\n        except Exception as e:\n             print(f\"Error copying train file {img_name}: {e}\")\n\n# Copy Test Data\nprint(\"Copying test images and labels...\")\ntest_image_files = glob.glob(os.path.join(original_test_images, '*.*'))\nfor img_src_path in test_image_files:\n    if os.path.isfile(img_src_path):\n        img_name = os.path.basename(img_src_path)\n        label_name = os.path.splitext(img_name)[0] + \".txt\"\n        label_src_path = os.path.join(original_test_labels, label_name)\n\n        img_dst_path = os.path.join(working_test_images, img_name)\n        label_dst_path = os.path.join(working_test_labels, label_name)\n\n        try:\n            shutil.copy2(img_src_path, img_dst_path)\n            if os.path.exists(label_src_path): # Copy label only if it exists\n                 shutil.copy2(label_src_path, label_dst_path)\n            # If label doesn't exist, it's a negative sample\n        except Exception as e:\n             print(f\"Error copying test file {img_name}: {e}\")\n\nprint(\"Finished copying data to working directory.\")\n\n\n# --- Step 2: Split Validation Set from the Working Training Data ---\nprint(f\"\\nSplitting {validation_split_percentage*100}% of data from working train set to working val set\")\n\n# Get the list of image files in the working train set\nimage_files = [os.path.basename(f) for f in glob.glob(os.path.join(working_train_images, '*.*')) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n\nif not image_files:\n    print(f\"Error: No image files found in working train folder {working_train_images}. Cannot split validation data.\")\nelse:\n    # Calculate the number of images to move to the validation set\n    num_val_images = int(validation_split_percentage * len(image_files))\n\n    if num_val_images == 0 and len(image_files) > 0:\n         print(f\"Info: Calculated 0 validation images. Will move at least 1 if total images > 0.\")\n         num_val_images = max(1, num_val_images) # Ensure at least one image if possible\n\n    if num_val_images > len(image_files):\n         print(f\"Warning: Number of validation images to move ({num_val_images}) is greater than total working train images ({len(image_files)}). Moving all images.\")\n         num_val_images = len(image_files)\n\n    print(f\"Moving {num_val_images} images and labels to validation set...\")\n\n    # Randomly select the images to move\n    try:\n        val_image_files = random.sample(image_files, num_val_images)\n\n        # Move the selected images and their corresponding labels to the validation set\n        moved_count = 0\n        skipped_label_count = 0\n        for image_file in val_image_files:\n            # Assume label filename is the same base name with .txt extension\n            base_name = os.path.splitext(image_file)[0]\n            label_file = base_name + \".txt\"\n\n            image_src = os.path.join(working_train_images, image_file)\n            image_dst = os.path.join(working_val_images, image_file)\n\n            label_src = os.path.join(working_train_labels, label_file)\n            label_dst = os.path.join(working_val_labels, label_file)\n\n            try:\n               shutil.move(image_src, image_dst)\n               if os.path.exists(label_src): # Only move label if it exists\n                   shutil.move(label_src, label_dst)\n               else:\n                   # This image might be a negative sample (no label file) - that's fine\n                   # print(f\"Info: Label file not found for {image_file} at {label_src}. Moving image only.\")\n                   skipped_label_count += 1\n               moved_count += 1\n            except Exception as e:\n                print(f\"Error moving file {image_file} or its label: {e}\")\n\n        print(f\"Finished splitting validation data. Moved {moved_count} images.\")\n        if skipped_label_count > 0:\n             print(f\"Info: {skipped_label_count} moved images did not have corresponding label files.\")\n\n    except ValueError as e:\n        print(f\"Error during random sampling: {e}. This might happen if the requested sample size ({num_val_images}) is larger than the population ({len(image_files)}).\")\n    except Exception as e:\n        print(f\"An unexpected error occurred during splitting: {e}\")\n\n\n# --- Step 3: Create data.yaml File ---\n# Place data.yaml in the working directory for easy access during training\ndata_yaml_path = os.path.join('/kaggle/working/', 'data.yaml')\n\n# The paths in data.yaml should be relative to the 'path' field, which is working_dataset_path\ndata_yaml_content = f\"\"\"\npath: {working_dataset_path} # Path to the dataset root directory in /kaggle/working\ntrain: train/images  # Relative path to train images from 'path'\nval: val/images # Relative path to validation images from 'path'\ntest: test/images # Relative path to test images from 'path'\n\nnc: {num_classes}  # Number of classes (Fire and Smoke)\nnames: {class_names} # Class names ['Fire', 'Smoke']. Order corresponds to IDs 0 and 1.\n\"\"\"\n\nprint(f\"\\nCreating data.yaml file at: {data_yaml_path}\")\ntry:\n    with open(data_yaml_path, 'w') as f:\n        f.write(data_yaml_content)\n    print(\"data.yaml created successfully.\")\n    print(\"\\nContent of data.yaml:\")\n    print(data_yaml_content)\nexcept Exception as e:\n    print(f\"Error creating data.yaml: {e}\")\n\n\nprint(f\"Data copied to working directory {working_dataset_path}.\")\nprint(f\"Validation set split created within the working copy.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:24:50.068050Z","iopub.execute_input":"2025-05-23T13:24:50.068330Z","iopub.status.idle":"2025-05-23T13:29:39.834114Z","shell.execute_reply.started":"2025-05-23T13:24:50.068306Z","shell.execute_reply":"2025-05-23T13:29:39.833497Z"}},"outputs":[{"name":"stdout","text":"Copying dataset from /kaggle/input/forest-fire-dataset to writable /kaggle/working/dfire_working_copy\nCopying train images and labels...\nCopying test images and labels...\nFinished copying data to working directory.\n\nSplitting 10.0% of data from working train set to working val set\nMoving 1722 images and labels to validation set...\nFinished splitting validation data. Moved 1722 images.\n\nCreating data.yaml file at: /kaggle/working/data.yaml\ndata.yaml created successfully.\n\nContent of data.yaml:\n\npath: /kaggle/working/dfire_working_copy # Path to the dataset root directory in /kaggle/working\ntrain: train/images  # Relative path to train images from 'path'\nval: val/images # Relative path to validation images from 'path'\ntest: test/images # Relative path to test images from 'path'\n\nnc: 2  # Number of classes (Fire and Smoke)\nnames: ['Fire', 'Smoke'] # Class names ['Fire', 'Smoke']. Order corresponds to IDs 0 and 1.\n\nData copied to working directory /kaggle/working/dfire_working_copy.\nValidation set split created within the working copy.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os # Import os to join path\n\n# Path to your data.yaml file\ndata_yaml_file = '/kaggle/working/data.yaml'\n\n# Load a model\nmodel = YOLO('yolov8s.pt')  # load an official model\n\n# Define project and run name\nPROJECT = 'fire_detection' # Or any project name\nNAME = 'yolov8s_dfire_split' # Name for this specific training run\n\nmodel.train(\n   data = 'data.yaml',\n   task = 'detect',\n   epochs = 100,\n   verbose = True,\n   batch = 64,\n   imgsz = 640,\n   patience = 20,\n   save = True,\n   device = 0,\n   workers = 8,\n   project = PROJECT,\n   name = NAME,\n   cos_lr = True,\n   lr0 = 0.0001,\n   lrf = 0.00001,\n   warmup_epochs = 3,\n   warmup_bias_lr = 0.000001,\n   optimizer = 'Adam',\n   seed = 42,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T08:27:50.181916Z","iopub.execute_input":"2025-05-23T08:27:50.182114Z","execution_failed":"2025-05-23T11:39:28.115Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 241MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.143 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=1e-05, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_dfire_split, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=fire_detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=fire_detection/yolov8s_dfire_split, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=1e-06, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 27.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \nModel summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n\nTransferred 349/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 127MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1882.0Â±1135.4 MB/s, size: 136.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dfire_working_copy/train/labels... 15499 images, 7060 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15499/15499 [00:09<00:00, 1620.69it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB02521.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB06626.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07271.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07278.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07297.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07312.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07534.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07536.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07539.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07540.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07541.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07542.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07552.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07554.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07555.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07556.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07562.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07639.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dfire_working_copy/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 499.1Â±135.4 MB/s, size: 134.3 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dfire_working_copy/val/labels... 1722 images, 773 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1722/1722 [00:01<00:00, 1307.90it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07199.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07305.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07535.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07538.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07543.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07557.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07559.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07561.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dfire_working_copy/val/labels.cache\nPlotting labels to fire_detection/yolov8s_dfire_split/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mfire_detection/yolov8s_dfire_split\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100        15G      1.709      2.962      1.624         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.581      0.527      0.548      0.277\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      15.1G      1.464      1.551      1.378         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.649      0.607      0.637      0.338\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      15.1G      1.429      1.339      1.346         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.685      0.595      0.663      0.359\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      15.1G      1.401      1.254       1.34         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.701      0.658       0.71      0.382\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      15.1G      1.374      1.192      1.316         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.749      0.627      0.717      0.402\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      15.1G      1.361      1.155      1.309         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.731      0.653      0.722        0.4\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      15.1G      1.346      1.105      1.291         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.718      0.684      0.745      0.411\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      15.1G      1.336       1.07      1.287         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.728      0.682      0.754      0.422\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100      15.1G      1.321      1.051      1.273         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.743      0.685      0.749      0.418\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100      15.1G      1.314      1.034      1.262         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.737       0.68      0.745      0.427\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100      15.1G        1.3      1.012      1.263         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.748      0.691      0.754      0.429\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100      15.1G      1.284     0.9836      1.249         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.756      0.685      0.764      0.434\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100      15.1G       1.28     0.9787      1.248         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.766      0.688      0.767      0.439\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100      15.1G      1.272      0.955      1.239         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.751        0.7      0.768      0.437\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100      15.1G      1.251     0.9404      1.233         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103       0.75      0.712      0.774      0.445\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100      15.1G      1.242     0.9062      1.222         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.765      0.702      0.767      0.443\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100      15.1G      1.242     0.9056      1.222         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.765      0.715      0.778      0.448\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100      15.1G      1.229       0.89      1.216         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.787      0.708       0.78       0.45\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/100      15.1G      1.222     0.8802      1.207         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:04<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.785      0.702      0.779      0.454\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/100      15.1G      1.213     0.8649      1.198         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.798      0.717      0.789      0.457\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/100      15.1G      1.204     0.8501      1.199         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.767      0.729      0.787      0.457\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     22/100      15.1G      1.201     0.8454      1.198         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.791      0.706      0.792      0.462\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     23/100      15.1G      1.198     0.8382      1.187         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.782      0.724      0.788      0.465\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     24/100      15.1G      1.176      0.819      1.179         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103       0.77      0.731      0.789      0.459\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     25/100      15.1G      1.177      0.811      1.182         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103       0.78      0.727      0.798      0.467\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     26/100      15.1G      1.167     0.8016      1.173         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.793      0.724      0.789      0.462\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     27/100      15.1G      1.161     0.7915      1.167         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.791       0.73      0.792      0.458\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     28/100      15.1G      1.157     0.7814      1.168         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.797       0.72      0.791      0.458\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     29/100      15.1G      1.147     0.7689      1.159         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.782       0.73      0.791       0.46\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     30/100      15.1G       1.14     0.7663      1.161         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103       0.79      0.739      0.802      0.474\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     31/100      15.1G      1.139      0.758      1.157         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.786      0.721      0.786      0.467\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     32/100      15.1G      1.122     0.7452      1.148         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.794      0.735      0.792      0.469\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     33/100      15.1G      1.113     0.7371      1.142         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.787      0.744      0.798      0.474\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     34/100      15.1G      1.111     0.7283       1.14         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.807       0.73      0.801      0.474\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     35/100      15.1G      1.102     0.7154      1.135         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.804      0.743      0.803      0.478\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     36/100      15.1G      1.099     0.7133      1.138         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.797      0.742      0.807      0.479\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     37/100      15.1G      1.083     0.7019      1.128         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103       0.79      0.747      0.802       0.48\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     38/100      15.1G      1.082     0.6958      1.125         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.794      0.747      0.806      0.483\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     39/100      15.1G      1.076      0.694      1.122         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.799      0.755      0.808      0.482\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     40/100      15.1G      1.067     0.6813      1.112         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.812      0.747      0.807      0.479\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     41/100      15.1G      1.056     0.6739      1.109         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.805      0.738      0.799      0.474\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     42/100      15.1G      1.055      0.672      1.108         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103       0.81      0.735      0.799      0.475\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     43/100      15.1G      1.052     0.6643      1.106         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2103      0.806      0.746      0.805       0.48\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     44/100      15.1G      1.047     0.6576        1.1        161        640:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 154/243 [02:35<01:29,  1.01s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(\"hi\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-23T11:39:28.116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lastpt44_model_path = r\"/kaggle/input/resuming-44th-epoch/44th_epoch_data/last.pt\"\nargs_yaml = r\"/kaggle/input/resuming-44th-epoch/44th_epoch_data/args.yaml\"\ndata_yaml_file = '/kaggle/working/data.yaml'\nresult_csv = r\"/kaggle/input/resuming-44th-epoch/44th_epoch_data/results (2).csv\"\nbestpt44_model_path = r\"/kaggle/input/resuming-44th-epoch/44th_epoch_data/best.pt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfrom ultralytics import YOLO\n\nprevious_run_output_dir = r\"/kaggle/input/resuming-44th-epoch/44th_epoch_data\" # <<< VERIFY THIS PATH\n\nlastpt44_model_path = os.path.join(previous_run_output_dir, \"last.pt\")\n# args.yaml and best.pt are expected in the same directory and will be used by YOLOv8\n\n# Path to your data.yaml file in your current working directory (/kaggle/working)\n# Make sure you have a copy of this file in /kaggle/working for this session\ndata_yaml_file = '/kaggle/working/data.yaml' # <<< VERIFY THIS PATH is correct for THIS session\n\n\n\nprint(f\"Loading model from checkpoint: {lastpt44_model_path}\")\ntry:\n    model = YOLO(lastpt44_model_path)\n    print(\"Model loaded successfully.\")\nexcept FileNotFoundError:\n    print(f\"Error: Checkpoint file not found at {lastpt44_model_path}. Please verify the path.\")\n    # You would typically stop execution here if the checkpoint is not found\n\n\n# --- Step 2: Resume Training ---\nprint(\"\\nResuming training...\")\n\n\nPROJECT = 'fire_detection' # Original project name\nNAME = 'yolov8s_dfire_split' # Original run name\n\n\ntry:\n    model.train(\n       data = data_yaml_file, # Provide the data.yaml path for this session\n       task = 'detect',\n       epochs = 100,\n       verbose = True,\n       batch = 64,\n       imgsz = 640,\n       patience = 10,\n       save = True,\n       device = 0,\n       workers = 8,\n       project = PROJECT,\n       name = NAME,\n       cos_lr = True,\n       lr0 = 0.0001,\n       lrf = 0.00001,\n       warmup_epochs = 3,\n       warmup_bias_lr = 0.000001,\n       optimizer = 'Adam',\n       seed = 42,        # Usually loaded from args.yaml\n    )\n    print(\"\\nTraining resumed successfully.\")\n\nexcept Exception as e:\n    print(f\"\\nAn error occurred during training: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:09:48.256268Z","iopub.execute_input":"2025-05-23T12:09:48.256628Z","iopub.status.idle":"2025-05-23T12:57:06.404027Z","shell.execute_reply.started":"2025-05-23T12:09:48.256599Z","shell.execute_reply":"2025-05-23T12:57:06.402995Z"}},"outputs":[{"name":"stdout","text":"Loading model from checkpoint: /kaggle/input/resuming-44th-epoch/44th_epoch_data/last.pt\nModel loaded successfully.\n\nResuming training...\nUltralytics 8.3.143 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=1e-05, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/input/resuming-44th-epoch/44th_epoch_data/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_dfire_split3, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=fire_detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=fire_detection/yolov8s_dfire_split3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=1e-06, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \nModel summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1890.8Â±1176.4 MB/s, size: 131.2 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dfire_working_copy/train/labels.cache... 15499 images, 7025 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15499/15499 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB02521.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07199.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07271.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07278.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07297.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07305.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07312.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07534.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07535.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07536.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07538.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07539.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07540.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07541.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07542.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07543.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07552.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07554.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07555.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07556.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07557.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07559.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07561.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07562.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07639.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 346.3Â±181.0 MB/s, size: 208.3 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dfire_working_copy/val/labels.cache... 1722 images, 808 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1722/1722 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB06626.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to fire_detection/yolov8s_dfire_split3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mfire_detection/yolov8s_dfire_split3\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      13.6G      1.023     0.6333      1.094         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.918      0.882      0.935      0.681\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      15.5G      1.034     0.6464      1.103         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039        0.9      0.866      0.925      0.653\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      15.5G      1.072     0.6957      1.117         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.874       0.84      0.903      0.616\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      15.5G        1.1     0.7287      1.136         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.842      0.828      0.893      0.598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      15.5G      1.102     0.7286      1.136         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.876      0.817       0.89      0.594\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      15.5G      1.101     0.7279       1.14         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.862        0.8      0.877      0.585\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      15.5G      1.106      0.725      1.136         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.879      0.786       0.88      0.571\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      15.5G      1.096     0.7181      1.132         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.863       0.79      0.878      0.572\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100      15.5G      1.092     0.7264      1.127         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.55it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.839      0.801       0.87      0.566\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100      15.5G      1.094     0.7201      1.128         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.841      0.783      0.863      0.559\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100      15.5G      1.088     0.7184      1.127         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.863      0.789      0.872      0.569\n\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 1, best model saved as best.pt.\nTo update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n11 epochs completed in 0.781 hours.\nOptimizer stripped from fire_detection/yolov8s_dfire_split3/weights/last.pt, 22.5MB\nOptimizer stripped from fire_detection/yolov8s_dfire_split3/weights/best.pt, 22.5MB\n\nValidating fire_detection/yolov8s_dfire_split3/weights/best.pt...\nUltralytics 8.3.143 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:11<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2039      0.919      0.881      0.936      0.681\n                  Fire        807        916      0.954      0.922       0.96      0.756\n                 Smoke        457       1123      0.884      0.841      0.912      0.606\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1mfire_detection/yolov8s_dfire_split3\u001b[0m\n\nTraining resumed successfully.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO('project_name/experiment_name/weights/best.pt')\nmodel.val(split='test', batch=48, imgsz=640, verbose=True, conf = 0.1, iou = 0.5)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-23T13:20:45.974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfrom ultralytics import YOLO\n\nprevious_run_output_dir = r\"/kaggle/input/resuming-44th-epoch/44th_epoch_data\" # <<< VERIFY THIS PATH\n\nbestpt44_model_path = os.path.join(previous_run_output_dir, \"best.pt\")\n# args.yaml and best.pt are expected in the same directory and will be used by YOLOv8\n\n# Path to your data.yaml file in your current working directory (/kaggle/working)\n# Make sure you have a copy of this file in /kaggle/working for this session\ndata_yaml_file = '/kaggle/working/data.yaml' # <<< VERIFY THIS PATH is correct for THIS session\n\n\n\nprint(f\"Loading model from checkpoint: {bestpt44_model_path}\")\ntry:\n    model = YOLO(bestpt44_model_path)\n    print(\"Model loaded successfully.\")\nexcept FileNotFoundError:\n    print(f\"Error: Checkpoint file not found at {bestpt44_model_path}. Please verify the path.\")\n    # You would typically stop execution here if the checkpoint is not found\n\n\n# --- Step 2: Resume Training ---\nprint(\"\\nResuming training...\")\n\n\nPROJECT = 'fire_detection' # Original project name\nNAME = 'yolov8s_dfire_split' # Original run name\n\n\ntry:\n    model.train(\n       data = data_yaml_file, # Provide the data.yaml path for this session\n       task = 'detect',\n       epochs = 100,\n       verbose = True,\n       batch = 64,\n       imgsz = 640,\n       patience = 10,\n       save = True,\n       device = 0,\n       workers = 8,\n       project = PROJECT,\n       name = NAME,\n       cos_lr = True,\n       lr0 = 0.0001,\n       lrf = 0.00001,\n       warmup_epochs = 3,\n       warmup_bias_lr = 0.000001,\n       optimizer = 'Adam',\n       seed = 42,        # Usually loaded from args.yaml\n    )\n    print(\"\\nTraining resumed successfully.\")\n\nexcept Exception as e:\n    print(f\"\\nAn error occurred during training: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T13:29:39.834751Z","iopub.execute_input":"2025-05-23T13:29:39.834929Z","iopub.status.idle":"2025-05-23T14:17:26.841157Z","shell.execute_reply.started":"2025-05-23T13:29:39.834915Z","shell.execute_reply":"2025-05-23T14:17:26.840160Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nLoading model from checkpoint: /kaggle/input/resuming-44th-epoch/44th_epoch_data/best.pt\nModel loaded successfully.\n\nResuming training...\nUltralytics 8.3.143 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=1e-05, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/input/resuming-44th-epoch/44th_epoch_data/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_dfire_split, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=fire_detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=fire_detection/yolov8s_dfire_split, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=1e-06, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 20.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \nModel summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 108MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2123.4Â±928.5 MB/s, size: 147.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dfire_working_copy/train/labels... 15499 images, 7087 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15499/15499 [00:09<00:00, 1684.67it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB02521.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB06626.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07199.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07271.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07278.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07297.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07305.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07312.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07534.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07535.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07536.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07538.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07540.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07541.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07543.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07552.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07554.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07555.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07557.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07561.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07562.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dfire_working_copy/train/images/WEB07639.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dfire_working_copy/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 454.8Â±101.9 MB/s, size: 106.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dfire_working_copy/val/labels... 1722 images, 746 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1722/1722 [00:00<00:00, 2039.18it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07539.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07542.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07556.jpg: corrupt JPEG restored and saved\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dfire_working_copy/val/images/WEB07559.jpg: corrupt JPEG restored and saved\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dfire_working_copy/val/labels.cache\nPlotting labels to fire_detection/yolov8s_dfire_split/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mfire_detection/yolov8s_dfire_split\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100        15G      1.053     0.6623      1.112         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.904      0.857      0.923       0.65\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      15.1G      1.064      0.679      1.117         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.897       0.84       0.91      0.622\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      15.1G      1.087     0.7097      1.127         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.867      0.813      0.893      0.589\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      15.1G      1.122     0.7566      1.148         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.842      0.823      0.882      0.577\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      15.1G      1.123     0.7483      1.144         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.839      0.801      0.862      0.548\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      15.1G      1.127     0.7571      1.149         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.872      0.773      0.868      0.563\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      15.1G      1.116     0.7394      1.142         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275       0.82      0.808      0.862      0.552\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      15.1G      1.124     0.7511      1.146         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.843      0.785      0.862      0.551\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100      15.1G      1.108     0.7286      1.138         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.836      0.792      0.863      0.548\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100      15.1G      1.115     0.7315      1.135         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.856       0.77      0.861      0.545\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100      15.1G      1.108     0.7318      1.137         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [04:05<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.845      0.781      0.856      0.537\n\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 1, best model saved as best.pt.\nTo update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n11 epochs completed in 0.781 hours.\nOptimizer stripped from fire_detection/yolov8s_dfire_split/weights/last.pt, 22.5MB\nOptimizer stripped from fire_detection/yolov8s_dfire_split/weights/best.pt, 22.5MB\n\nValidating fire_detection/yolov8s_dfire_split/weights/best.pt...\nUltralytics 8.3.143 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:11<00:00,  1.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1722       2275      0.907      0.854      0.923       0.65\n                  Fire        887       1002      0.943      0.914      0.963      0.732\n                 Smoke        498       1273      0.871      0.794      0.883      0.567\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 1.2ms postprocess per image\nResults saved to \u001b[1mfire_detection/yolov8s_dfire_split\u001b[0m\n\nTraining resumed successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T14:38:21.686609Z","iopub.execute_input":"2025-05-23T14:38:21.687249Z","iopub.status.idle":"2025-05-23T14:38:21.696504Z","shell.execute_reply.started":"2025-05-23T14:38:21.687208Z","shell.execute_reply":"2025-05-23T14:38:21.695905Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}